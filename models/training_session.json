{
  "policy_losses": [],
  "value_losses": [],
  "combined_losses": [],
  "learning_rates": [],
  "epochs": 0,
  "policy_final_loss": 0.841449674478797,
  "value_final_loss": 0.05175329153947556,
  "training_examples": 684,
  "minimax_games": 50
}